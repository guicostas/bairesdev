{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação do Transfer Learning\n",
    "\n",
    "1.  **Configuração do Ambiente no Colab**:\n",
    "    -   No Google Colab...\n",
    "    -   O ambiente deve estar configurado para usar GPU\n",
    "        (isso acelerará o treinamento da rede neural). Para isso, vá em\n",
    "        `Runtime` \\> `Change runtime type` e selecione `GPU` em\n",
    "        `Hardware accelerator`.\n",
    "2.  **Importação das Bibliotecas Necessárias**:\n",
    "    ``` python\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    import matplotlib.pyplot as plt\n",
    "    ```\n",
    "3.  **Carregamento e Pré-processamento do Dataset**:\n",
    "    -   Com o seu dataset, use-o aqui para carregá-lo no Colab. Se\n",
    "        estiver usando o dataset de gatos e cachorros, você pode seguir\n",
    "        o exemplo do link fornecido.\n",
    "    -   Vamos assumir que você tem um dataset com duas classes (por\n",
    "        exemplo, “gatos” e “cachorros”) organizado em pastas separadas\n",
    "        para cada classe.\n",
    "\n",
    "    ``` python\n",
    "    # Exemplo de carregamento de dados\n",
    "    train_dir = '/caminho/para/dataset/train'\n",
    "    validation_dir = '/caminho/para/dataset/validation'\n",
    "\n",
    "    # Pré-processamento das imagens\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "    ```\n",
    "4.  **Carregamento de um Modelo Pré-treinado**:\n",
    "    -   Vamos usar um modelo pré-treinado como base para o Transfer\n",
    "        Learning. O modelo `MobileNetV2` é uma escolha comum devido à\n",
    "        sua eficiência.\n",
    "\n",
    "    ``` python\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(150, 150, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    # Congelar o modelo base para que ele não seja treinado novamente\n",
    "    base_model.trainable = False\n",
    "    ```\n",
    "5.  **Adição de Camadas Personalizadas**:\n",
    "    -   Adicionamos camadas personalizadas no topo do modelo\n",
    "        pré-treinado para adaptá-lo ao nosso problema específico.\n",
    "\n",
    "    ``` python\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    ```\n",
    "6.  **Treinamento do Modelo**:\n",
    "    -   Agora, podemos treinar o modelo com nosso dataset.\n",
    "\n",
    "    ``` python\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "    )\n",
    "    ```\n",
    "7.  **Avaliação e Visualização dos Resultados**:\n",
    "    -   Após o treinamento, podemos avaliar o modelo e visualizar os\n",
    "        resultados.\n",
    "\n",
    "    ``` python\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    ```\n",
    "8.  **Fine-Tuning (Opcional)**:\n",
    "    -   Se desejar, você pode descongelar algumas camadas do modelo base\n",
    "        e realizar um fine-tuning para melhorar ainda mais o desempenho.\n",
    "\n",
    "    ``` python\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Recompilar o modelo\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Continuar o treinamento\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "    )\n",
    "    ```\n",
    "\n",
    "### Considerações Finais\n",
    "\n",
    "-   **Dataset Personalizado**: Se você estiver usando um dataset\n",
    "    personalizado, certifique-se de que as imagens estejam organizadas\n",
    "    em pastas separadas para cada classe e que o caminho para essas\n",
    "    pastas esteja correto no código.\n",
    "-   **Ajustes**: Dependendo do tamanho do seu dataset e da complexidade\n",
    "    do problema, você pode precisar ajustar hiperparâmetros como o\n",
    "    número de épocas, o tamanho do batch, ou até mesmo escolher um\n",
    "    modelo pré-treinado diferente.\n",
    "\n",
    "Se você puder compartilhar mais detalhes sobre o dataset que você tem,\n",
    "posso ajudar a ajustar o código para melhor atender às suas\n",
    "necessidades. Além disso, se você tiver alguma dúvida específica ou\n",
    "encontrar algum problema durante a implementação, sinta-se à vontade\n",
    "para perguntar!"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
